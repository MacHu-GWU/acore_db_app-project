# -*- coding: utf-8 -*-

"""
Consumer Price Index (CPI) æ˜¯ä¸€ä¸ªå¯¹é­”å…½ä¸–ç•Œä¸­çš„ç‰©å“ä»·æ ¼è¿›è¡Œä¿®æ­£, æŒ‰ç…§æ¯”è¾ƒç¨³å®šçš„ç§æœç‰©ä»·
ç»™è¿™äº›ç‰©å“çš„ä»·æ ¼èµ‹å€¼.
"""

import typing as T
import json
import gzip
import dataclasses

import polars as pl
import sqlalchemy as sa
from pathlib_mate import Path

from acore_df.api import Lookup

from ..common.api import craft_spell_recipe
from ...logger import logger

if T.TYPE_CHECKING:  # pragma: no cover
    from ...orm import Orm

lookup = Lookup.new()


@dataclasses.dataclass
class CpiWorkflow:
    """
    CPI db update workflow.
    """

    orm: "Orm" = dataclasses.field()
    dir_workspace: Path = dataclasses.field()

    @property
    def path_item_template_backup_json_gz(self) -> Path:
        return self.dir_workspace.joinpath("item_template_backup.json.gz")

    @property
    def path_lookup_table_tsv(self) -> Path:
        return self.dir_workspace.joinpath("lookup_table.tsv")

    @property
    def path_base_price_table_tsv(self) -> Path:
        return self.dir_workspace.joinpath("base-price-table.tsv")

    @property
    def path_price_table_tsv(self) -> Path:
        return self.dir_workspace.joinpath("price-table.tsv")

    @property
    def final_price_table_tsv(self) -> Path:
        return self.dir_workspace.joinpath("final-price-table.tsv")

    @logger.emoji_block(
        msg="{func_name}",
        emoji="ğŸ“„",
    )
    def backup_item_template(
        self,
        _limit: T.Optional[int] = None,
    ) -> T.List[T.Dict[str, T.Any]]:
        """
        å°†æ•°æ®åº“ä¸­çš„ ItemTemplate è¡¨çš„æ•°æ®å¯¼å‡ºå¹¶å¤‡ä»½åˆ° json æ–‡ä»¶ä¸­.
        """
        engine = self.orm.engine
        with engine.connect() as conn:
            t_item_template = self.orm.t_item_template
            t_item_template_locale = self.orm.t_item_template_locale
            sql_stmt = (
                sa.select(
                    t_item_template, t_item_template_locale.c.Name.label("name_cn")
                )
                .join(
                    t_item_template_locale,
                    onclause=t_item_template.c.entry == t_item_template_locale.c.ID,
                )
                .where(t_item_template_locale.c.locale == "zhCN")
            )
            logger.info("Read data from item_template table ...")
            item_template_records = [row._asdict() for row in conn.execute(sql_stmt)]
            logger.info(f"Done, got {len(item_template_records)} records.")

            logger.info(f"Dump data to {self.path_item_template_backup_json_gz} ...")
            self.path_item_template_backup_json_gz.write_bytes(
                gzip.compress(
                    json.dumps(item_template_records, ensure_ascii=False).encode(
                        "utf-8"
                    )
                )
            )
            logger.info(f"Done, see: file://{self.path_item_template_backup_json_gz}")
        return item_template_records

    @logger.emoji_block(
        msg="{func_name}",
        emoji="ğŸ“„",
    )
    def generate_base_price_table(self) -> pl.DataFrame:
        """
        ç”Ÿæˆä¸€ä¸ªåŒ…å«æ‰€æœ‰ç‰©å“åˆ—è¡¨, ä½†æ˜¯æ²¡æœ‰ä»·æ ¼çš„åŸºç¡€ price table. ç„¶åæˆ‘æ‰èƒ½åœ¨è¿™ä¸ªè¡¨ä¸­
        å¡«å…¥ç‰©å“ä»·å€¼. åœ¨ price table ä¸­çš„ç‰©å“éƒ½æ˜¯æˆ‘è®¤ä¸º "å¯ä»¥" ä» NPC å¤„è´­ä¹°çš„ç‰©å“. åŒ…æ‹¬:

        1. å„ç§å•†å“.
        2. å„ç§é…æ–¹.
        3. å„ç§æ¯ä¸ªç‰ˆæœ¬æ»¡çº§åçš„è£…å¤‡.

        ç”Ÿæˆçš„è¡¨ç»“æ„å¯ä»¥å‚è€ƒ: https://docs.google.com/spreadsheets/d/1e4I2-d4JyVbsvOcdePruqev-rkyYYMUPrwkI_fieIYw/edit?gid=2104698923#gid=2104698923
        """
        logger.info(f"Load data from {self.path_item_template_backup_json_gz} ...")
        records = json.loads(
            gzip.decompress(self.path_item_template_backup_json_gz.read_bytes()).decode(
                "utf-8"
            )
        )
        logger.info(f"total records = {len(records)}")

        logger.info(f"Transform data ...")
        df = pl.DataFrame(records)

        df = df.select(
            [
                "entry",
                "name_cn",
                "class",
                "subclass",
                "Quality",
                "bonding",
                "ItemLevel",
                "RequiredLevel",
            ]
        )
        df = df.rename(
            mapping={
                "entry": "ç¼–å·",
                "name_cn": "åå­—",
                "class": "å¤§ç±»",
                "subclass": "å°ç±»",
                "Quality": "å“è´¨",
                "bonding": "ç»‘å®š",
                "ItemLevel": "iLvl",
                "RequiredLevel": "rLvl",
            }
        )

        df = df.with_columns(
            pl.concat_str(
                pl.col("å¤§ç±»"),
                pl.lit("-"),
                pl.col("å°ç±»"),
            ).alias("item_class")
        )

        logger.info(f"Filter data by item class and subclass ...")
        df = df.filter(
            # https://docs.google.com/spreadsheets/d/1XevE2tFnjCSf0paizwanCJMgmBdChunCgAp7BvqqD0M/edit?gid=0#gid=0
            pl.col("item_class").is_in(
                [
                    "0-0",  # æ¶ˆè€—å“-æ¶ˆè€—å“
                    "0-1",  # æ¶ˆè€—å“-è¯æ°´
                    "0-2",  # æ¶ˆè€—å“-è¯å‰‚
                    "0-3",  # æ¶ˆè€—å“-åˆå‰‚
                    "0-4",  # æ¶ˆè€—å“-å·è½´
                    "0-5",  # æ¶ˆè€—å“-é£Ÿç‰©å’Œé¥®æ–™
                    "0-6",  # æ¶ˆè€—å“-ç‰©å“å¼ºåŒ–
                    "0-7",  # æ¶ˆè€—å“-ç»·å¸¦
                    "0-8",  # æ¶ˆè€—å“-å…¶ä»–
                    "1-0",  # å®¹å™¨-èƒŒåŒ…
                    "1-1",  # å®¹å™¨-çµé­‚è¢‹
                    "1-2",  # å®¹å™¨-è‰è¯åŒ…
                    "1-3",  # å®¹å™¨-é™„é­”ææ–™åŒ…
                    "1-4",  # å®¹å™¨-å·¥ç¨‹å­¦ææ–™åŒ…
                    "1-5",  # å®¹å™¨-å®çŸ³åŒ…
                    "1-6",  # å®¹å™¨-çŸ¿çŸ³è¢‹
                    "1-7",  # å®¹å™¨-åˆ¶çš®ææ–™åŒ…
                    "1-8",  # å®¹å™¨-é“­æ–‡åŒ…
                    "2-0",  # æ­¦å™¨-å•æ‰‹æ–§
                    "2-1",  # æ­¦å™¨-åŒæ‰‹æ–§
                    "2-2",  # æ­¦å™¨-å¼“
                    "2-3",  # æ­¦å™¨-æª
                    "2-4",  # æ­¦å™¨-å•æ‰‹é”¤
                    "2-5",  # æ­¦å™¨-åŒæ‰‹é”¤
                    "2-6",  # æ­¦å™¨-é•¿æŸ„æ­¦å™¨
                    "2-7",  # æ­¦å™¨-å•æ‰‹å‰‘
                    "2-8",  # æ­¦å™¨-åŒæ‰‹å‰‘
                    # "2-9",  # -
                    "2-10",  # æ­¦å™¨-æ³•æ–
                    # "2-11",  # -
                    # "2-12",  # -
                    "2-13",  # æ­¦å™¨-æ‹³å¥—
                    "2-14",  # æ­¦å™¨-æ‚é¡¹
                    "2-15",  # æ­¦å™¨-åŒ•é¦–
                    "2-16",  # æ­¦å™¨-æŠ•æ·æ­¦å™¨
                    # "2-17",  # -
                    "2-18",  # æ­¦å™¨-å¼©
                    "2-19",  # æ­¦å™¨-é­”æ–
                    "2-20",  # æ­¦å™¨-é’“é±¼ç«¿
                    "3-0",  # ç å®-çº¢è‰²
                    "3-1",  # ç å®-è“è‰²
                    "3-2",  # ç å®-é»„è‰²
                    "3-3",  # ç å®-ç´«è‰²
                    "3-4",  # ç å®-ç»¿è‰²
                    "3-5",  # ç å®-æ©™è‰²
                    "3-6",  # ç å®-å¤šå½©
                    "3-7",  # ç å®-ç®€å•
                    "3-8",  # ç å®-æ£±å½©
                    "4-0",  # æŠ¤ç”²-æ‚é¡¹
                    "4-1",  # æŠ¤ç”²-å¸ƒç”²
                    "4-2",  # æŠ¤ç”²-çš®ç”²
                    "4-3",  # æŠ¤ç”²-é”ç”²
                    "4-4",  # æŠ¤ç”²-æ¿ç”²
                    # "4-5",  # -
                    "4-6",  # æŠ¤ç”²-ç›¾ç‰Œ
                    "4-7",  # æŠ¤ç”²-åœ£å¥‘
                    "4-8",  # æŠ¤ç”²-ç¥åƒ
                    "4-9",  # æŠ¤ç”²-å›¾è…¾
                    "4-10",  # æŠ¤ç”²-é­”å°
                    "5-0",  # ææ–™-æ–½æ³•ææ–™
                    # "6-0",  # -
                    # "6-1",  # -
                    "6-2",  # å¼¹è¯-ç®­
                    "6-3",  # å¼¹è¯-å­å¼¹
                    # "6-4",  # -
                    # "7-0",  # å•†å“-å•†å“
                    "7-1",  # å•†å“-é›¶ä»¶
                    "7-2",  # å•†å“-çˆ†ç‚¸ç‰©
                    "7-3",  # å•†å“-è£…ç½®
                    "7-4",  # å•†å“-ç å®åŠ å·¥
                    "7-5",  # å•†å“-å¸ƒæ–™
                    "7-6",  # å•†å“-çš®é©
                    "7-7",  # å•†å“-é‡‘å±ä¸çŸ³å¤´
                    "7-8",  # å•†å“-è‚‰ç±»
                    "7-9",  # å•†å“-è‰è¯
                    "7-10",  # å•†å“-å…ƒç´ 
                    "7-11",  # å•†å“-å…¶ä»–
                    "7-12",  # å•†å“-é™„é­”
                    "7-13",  # å•†å“-åŸæ–™
                    "7-14",  # å•†å“-æŠ¤ç”²é™„é­”
                    "7-15",  # å•†å“-æ­¦å™¨é™„é­”
                    # "8-0",  # -
                    "9-0",  # é…æ–¹-ä¹¦ç±
                    "9-1",  # é…æ–¹-åˆ¶çš®
                    "9-2",  # é…æ–¹-è£ç¼
                    "9-3",  # é…æ–¹-å·¥ç¨‹å­¦
                    "9-4",  # é…æ–¹-é”»é€ 
                    "9-5",  # é…æ–¹-çƒ¹é¥ª
                    "9-6",  # é…æ–¹-ç‚¼é‡‘æœ¯
                    "9-7",  # é…æ–¹-æ€¥æ•‘
                    "9-8",  # é…æ–¹-é™„é­”
                    "9-9",  # é…æ–¹-é’“é±¼
                    "9-10",  # é…æ–¹-ç å®åŠ å·¥
                    # "10-0",  # -
                    # "11-0",  # -
                    # "11-1",  # -
                    "11-2",  # ç®­è¢‹-ç®­è¢‹
                    "11-3",  # ç®­è¢‹-å¼¹è¯åŒ…
                    # "12-0",  # ä»»åŠ¡-ä»»åŠ¡
                    "13-0",  # é’¥åŒ™-é’¥åŒ™
                    # "13-1",  # é’¥åŒ™-å¼€é”å·¥å…·
                    # "14-0",  # æ°¸ä¹…-æ°¸ä¹…
                    # "15-0",  # å…¶å®ƒ-åƒåœ¾
                    "15-1",  # å…¶å®ƒ-æ–½æ³•ææ–™
                    "15-2",  # å…¶å®ƒ-å® ç‰©
                    "15-3",  # å…¶å®ƒ-èŠ‚æ—¥
                    "15-4",  # å…¶å®ƒ-å…¶ä»–
                    "15-5",  # å…¶å®ƒ-åéª‘
                    "16-1",  # é›•æ–‡-æˆ˜å£«
                    "16-2",  # é›•æ–‡-åœ£éª‘å£«
                    "16-3",  # é›•æ–‡-çŒäºº
                    "16-4",  # é›•æ–‡-ç›—è´¼
                    "16-5",  # é›•æ–‡-ç‰§å¸ˆ
                    "16-6",  # é›•æ–‡-æ­»äº¡éª‘å£«
                    "16-7",  # é›•æ–‡-è¨æ»¡
                    "16-8",  # é›•æ–‡-æ³•å¸ˆ
                    "16-9",  # é›•æ–‡-æœ¯å£«
                    "16-11",  # é›•æ–‡-å¾·é²ä¼Š
                ]
            ),
            pl.col("å“è´¨").is_in(
                [
                    # 0, # ç°è‰²
                    1,  # ç™½è‰²
                    2,  # ç»¿è‰²
                    3,  # è“è‰²
                    4,  # ç´«è‰²
                    5,  # æ©™è‰²
                    # 6, # çº¢è‰²
                    # 7, # é‡‘è‰²
                ]
            ),
        )
        print(f"filtered records = {df.shape[0]}")

        # Join with recipe
        logger.info(f"Add recipe data by join with craft spell recipe data ...")
        df_recipe = craft_spell_recipe.get_dataframe()
        df_recipe = df_recipe.rename({"count": "product_count"})
        df = df.join(
            df_recipe,
            left_on="ç¼–å·",
            right_on="id",
            how="left",
        )

        # Convert value and select columns
        id_to_name_mapping = {
            dct["ç¼–å·"]: dct["åå­—"] for dct in df.select(["ç¼–å·", "åå­—"]).to_dicts()
        }
        df = (
            df.drop("å°ç±»")
            .with_columns(
                pl.col("å¤§ç±»").replace(
                    {
                        id: row.name_cn
                        for id, row in lookup.item_template_class.row_map.items()
                    }
                ),
                pl.col("item_class")
                .replace(
                    {
                        id: row.subclass_name_cn
                        for id, row in lookup.item_template_subclass.row_map.items()
                    }
                )
                .alias("å°ç±»"),
                pl.col("å“è´¨").replace(
                    {
                        id: row.name_cn
                        for id, row in lookup.item_template_quality.row_map.items()
                    }
                ),
                pl.col("ç»‘å®š").replace(
                    {
                        id: row.name_cn
                        for id, row in lookup.item_template_bonding.row_map.items()
                    }
                ),
                pl.col("reagent_id_1")
                .replace(id_to_name_mapping)
                .alias("reagent_name_1"),
                pl.col("reagent_id_2")
                .replace(id_to_name_mapping)
                .alias("reagent_name_2"),
                pl.col("reagent_id_3")
                .replace(id_to_name_mapping)
                .alias("reagent_name_3"),
                pl.col("reagent_id_4")
                .replace(id_to_name_mapping)
                .alias("reagent_name_4"),
                pl.col("reagent_id_5")
                .replace(id_to_name_mapping)
                .alias("reagent_name_5"),
                pl.col("reagent_id_6")
                .replace(id_to_name_mapping)
                .alias("reagent_name_6"),
            )
            .select(
                [
                    "ç¼–å·",
                    "åå­—",
                    pl.lit(-1).alias("å•ä»·"),
                    pl.lit(1).alias("å¢å€¼"),
                    pl.lit(None).alias("å¯ä¹°"),
                    "å¤§ç±»",
                    "å°ç±»",
                    "å“è´¨",
                    "ç»‘å®š",
                    "iLvl",
                    "rLvl",
                    "product_count",
                    "reagent_id_1",
                    "reagent_name_1",
                    "reagent_count_1",
                    "reagent_id_2",
                    "reagent_name_2",
                    "reagent_count_2",
                    "reagent_id_3",
                    "reagent_name_3",
                    "reagent_count_3",
                    "reagent_id_4",
                    "reagent_name_4",
                    "reagent_count_4",
                    "reagent_id_5",
                    "reagent_name_5",
                    "reagent_count_5",
                    "reagent_id_6",
                    "reagent_name_6",
                    "reagent_count_6",
                ]
            )
        )

        logger.info(f"Dump data to {self.path_base_price_table_tsv} ...")
        df.write_csv(
            str(self.path_base_price_table_tsv),
            separator="\t",
        )
        logger.info(f"Done, see: file://{self.path_base_price_table_tsv}")

        return df

    @logger.emoji_block(
        msg="{func_name}",
        emoji="ğŸ“„",
    )
    def generate_final_price_table(self):
        """
        ç”ŸæˆåŒ…å«æ‰€æœ‰ç‰©å“çš„å•ä»·çš„ final price table. è¿™ä¸ªè¡¨æ˜¯æ ¹æ® base price table
        è®¡ç®—å¾—æ¥. åœ¨ base price table ä¸­åªæœ‰åŸå­ç±»çš„ç‰©å“çš„å•ä»· (åŸå­ç±»ç‰©å“å°±æ˜¯æ— æ³•é€šè¿‡
        å…¶ä»–ç‰©å“åˆæˆçš„ç‰©å“). åœ¨ final price table ä¸­, æˆ‘ä»¬ä¼šå°½å¯èƒ½çš„è®¡ç®—å‡ºæ‰€æœ‰ç‰©å“çš„
        å•ä»·.

        ç”Ÿæˆçš„è¡¨ç»“æ„å¯ä»¥å‚è€ƒ: https://docs.google.com/spreadsheets/d/1e4I2-d4JyVbsvOcdePruqev-rkyYYMUPrwkI_fieIYw/edit?gid=1949060708#gid=1949060708
        """
        # ä» price table ä¸­è¯»å–æ‰€éœ€çš„æ•°æ®
        logger.info(f"Load data from {self.path_price_table_tsv} ...")
        df = pl.read_csv(
            str(self.path_price_table_tsv),
            separator="\t",
            schema={
                "ç¼–å·": pl.Int32,
                "åå­—": pl.Utf8,
                "å•ä»·": pl.Float32,
                "å¢å€¼": pl.Float32,
                "å¯ä¹°": pl.Int32,
                "å¤§ç±»": pl.Utf8,
                "å°ç±»": pl.Utf8,
                "å“è´¨": pl.Utf8,
                "ç»‘å®š": pl.Utf8,
                "iLvl": pl.Int32,
                "rLvl": pl.Int32,
                "product_count": pl.Int32,
                "reagent_id_1": pl.Int32,
                "reagent_name_1": pl.Utf8,
                "reagent_count_1": pl.Float32,
                "reagent_id_2": pl.Int32,
                "reagent_name_2": pl.Utf8,
                "reagent_count_2": pl.Float32,
                "reagent_id_3": pl.Int32,
                "reagent_name_3": pl.Utf8,
                "reagent_count_3": pl.Float32,
                "reagent_id_4": pl.Int32,
                "reagent_name_4": pl.Utf8,
                "reagent_count_4": pl.Float32,
                "reagent_id_5": pl.Int32,
                "reagent_name_5": pl.Utf8,
                "reagent_count_5": pl.Float32,
                "reagent_id_6": pl.Int32,
                "reagent_name_6": pl.Utf8,
                "reagent_count_6": pl.Float32,
            },
        )
        # å»ºç«‹ä¸€ä¸ªå†…å­˜ä¸­çš„ id -> row çš„æ˜ å°„
        mapping = {row["ç¼–å·"]: row for row in df.to_dicts()}

        logger.info(f"extract reagents ...")
        def extract_reagents(row: T.Dict[str, T.Any]) -> T.Dict[int, int]:
            """
            ä» row ä¸­æŠŠå¤šä¸ª column çš„å€¼åˆå¹¶æˆä¸€ä¸ª reagents å­—æ®µ. reagents å­—æ®µæ˜¯ä¸€ä¸ªå­—å…¸,
            key æ˜¯ reagent_id, value æ˜¯ reagent_count.
            """
            reagents = {}
            for i in range(1, 1 + 6):
                id = row[f"reagent_id_{i}"]
                if id:
                    reagents[id] = row[f"reagent_count_{i}"]
            return reagents

        # å…ˆè·å¾—æ‰€æœ‰ item çš„ reagents
        for id, row in mapping.items():
            reagents = extract_reagents(row)
            mapping[id]["reagents"] = reagents

        logger.info(f"resolve price ...")
        def resolve_price():
            """
            è¿™ä¸ªå‡½æ•°ä¼šéå†æ‰€æœ‰ item, å°è¯•è®¡ç®—å‡ºå•ä»·. ç”±äºå¾ˆå¯èƒ½ item é…æ–¹ä¸­çš„ reagent
            çš„å•ä»·è¿˜æ²¡æœ‰è®¡ç®—å‡ºæ¥, è¦æ­£ç¡®è®¡ç®—å°±éœ€è¦ç”¨åˆ°é€’å½’ç¼–ç¨‹. è¿™é‡Œæˆ‘ä»¬å·æ‡’äº†, å°±ç”¨å¤šæ¬¡
            å¾ªç¯æ¥æ¨¡æ‹Ÿé€’å½’, ç›´åˆ°å†ä¹Ÿæ— æ³•æ‰¾åˆ°ä»»ä½•ä¸€ä¸ªæ–°çš„ item èƒ½è®¡ç®—å‡ºå•ä»·ä¸ºæ­¢.
            """
            counter = 0
            for id, row in mapping.items():
                price = row["å•ä»·"]
                if price == -1:
                    reagents = row["reagents"]
                    if reagents:
                        total_price = 0
                        found_total_price = True
                        for reg_id, reg_count in reagents.items():
                            try:
                                reg_price = mapping[reg_id]["å•ä»·"]
                            except KeyError:
                                found_total_price = False
                                break
                            if reg_price == -1:
                                found_total_price = False
                                break
                            else:
                                total_price += reg_price * reg_count
                        if found_total_price:
                            unit_price = total_price / row["product_count"]
                            mapping[id]["å•ä»·"] = unit_price
                            counter += 1
            return counter

        # å¾ªç¯åæ¬¡, ç›´åˆ°æ²¡æœ‰æ–°ç‰©å“æ—¢å¯
        for ith in range(1, 1 + 10):
            logger.info(f"--- {ith} iteration ---")
            counter = resolve_price()
            logger.info(f"resolved {counter} items")
            if counter == 0:
                break

        # æˆ‘ä»¬ä¸éœ€è¦ reagents åˆ—äº†
        for id, row in mapping.items():
            del row["reagents"]

        # é‡æ–°æ’åˆ—ä¸€ä¸‹ column å‡†å¤‡è¾“å‡º
        df = pl.DataFrame(list(mapping.values()), infer_schema_length=99999)
        df = df.select(
            [
                "ç¼–å·",
                "åå­—",
                "å•ä»·",
                "å¢å€¼",
                "å¯ä¹°",
            ]
        )
        df = df.filter(pl.col("å•ä»·") != -1)
        df = df.with_columns((pl.col("å•ä»·") * 10000).cast(int))

        logger.info(f"Dump data to {self.final_price_table_tsv} ...")
        df.write_csv(str(self.final_price_table_tsv), separator="\t")
        logger.info(f"Done, see: file://{self.final_price_table_tsv}")
